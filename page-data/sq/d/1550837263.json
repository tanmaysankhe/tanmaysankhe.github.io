{"data":{"jobs":{"edges":[{"node":{"frontmatter":{"title":"AirNote â€“ Pen it Down!","tabname":"AirNote","company":"IEEE","location":"Kanpur, India","range":"06-08 July 2019","url":"https://ieeexplore.ieee.org/document/8944690"},"html":"<ul>\n<li>Writing is a mode of coherent communication which can effectively convey our thoughts. Today, typing and writing are the usual modes of recording information. Another technique that is rapidly gaining popularity is air-writing. It refers to writing characters or words in free space using an air-pen or a finger. It differs from conventional writing methods as there is no pen-up and pen-down motion. With the evolution of smart wearables, the digital world can now be controlled with human gestures. These wearables are capable of perceiving and comprehending our actions. Our project capitalizes on this need gap, by focusing on creating a motion-to-text converter that would potentially act as software for the smart wearables for air-writing. This project is a point gesture detector-cum-identifier. We will use computer vision to trace the trajectory of finger and machine learning to recognize the word (out of the image that is formed through the action of motions). This will make air-writing possible. The generated text can be further be used for various purposes such as sending messages, mail, etc. It will prove to be a powerful communication tool for those with hearing difficulties. It will be an efficient way to communicate and will reduce the usage of mobile phones as well as notebooks, thereby making the actions of writing and texting redundant.</li>\n</ul>"}},{"node":{"frontmatter":{"title":"Futuristic Finger and its Modern Day Applications","tabname":"Futuristic Finger..","company":"IEEE","location":"Ghaziabad, India","range":"27-28 September 2019","url":"https://ieeexplore.ieee.org/document/8977629"},"html":"<ul>\n<li>Gesture regulated systems controlled by smart wearables have spearheaded the next epoch in human machine interaction. Gestures being intuitive and expressive are a more convenient way of communication. However, for developing a gesture controlled system, we need to accurately detect fingertips. In this paper, we present a fingertip detection system that can be efficiently used by smart wearables. This approach is free of markers and centroid-based techniques which are traditionally used to detect fingertips.The system's functionality is controlled by the number of fingertips in the frame. We collated a customized dataset, `1-2-3-4 Hands', which contained the images of different hands gesturing using one to four fingers. Using Faster RCNN with Inception v2 module, we trained this dataset to build a model capable of recognizing any of the first four fingertips, excluding the thumb. The count of fingertips is used to perform an action in real-time gesture controlled systems. Finally, we have implemented finger-control solutions such as AirWriting, AirDrawing, and Gaming Controls and enlisted their benefits.</li>\n</ul>"}}]}}}